<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="com.liubo.hadoop.dao.mapper.FileInfoMapper">
  <resultMap id="BaseResultMap" type="com.liubo.hadoop.dao.entity.FileInfo">
    <id column="id" jdbcType="INTEGER" property="id" />
    <result column="file_no" jdbcType="VARCHAR" property="fileNo" />
    <result column="file_name" jdbcType="VARCHAR" property="fileName" />
    <result column="file_type" jdbcType="VARCHAR" property="fileType" />
    <result column="file_author" jdbcType="VARCHAR" property="fileAuthor" />
    <result column="file_desc" jdbcType="VARCHAR" property="fileDesc" />
    <result column="file_size" jdbcType="BIGINT" property="fileSize" />
    <result column="file_url" jdbcType="VARCHAR" property="fileUrl" />
    <result column="user_id" jdbcType="VARCHAR" property="userId" />
    <result column="create_time" jdbcType="TIMESTAMP" property="createTime" />
    <result column="update_time" jdbcType="TIMESTAMP" property="updateTime" />
  </resultMap>
  <sql id="Base_Column_List">
    id, file_no, file_name, file_type, file_author, file_desc, file_size, file_url, user_id, 
    create_time, update_time
  </sql>
  <select id="selectByPrimaryKey" parameterType="java.lang.Integer" resultMap="BaseResultMap">
    select 
    <include refid="Base_Column_List" />
    from file_info
    where id = #{id,jdbcType=INTEGER}
  </select>
  <delete id="deleteByPrimaryKey" parameterType="java.lang.Integer">
    delete from file_info
    where id = #{id,jdbcType=INTEGER}
  </delete>
  <insert id="insert" parameterType="com.liubo.hadoop.dao.entity.FileInfo">
    insert into file_info (id, file_no, file_name, 
      file_type, file_author, file_desc, 
      file_size, file_url, user_id, 
      create_time, update_time)
    values (#{id,jdbcType=INTEGER}, #{fileNo,jdbcType=VARCHAR}, #{fileName,jdbcType=VARCHAR}, 
      #{fileType,jdbcType=VARCHAR}, #{fileAuthor,jdbcType=VARCHAR}, #{fileDesc,jdbcType=VARCHAR}, 
      #{fileSize,jdbcType=BIGINT}, #{fileUrl,jdbcType=VARCHAR}, #{userId,jdbcType=VARCHAR}, 
      #{createTime,jdbcType=TIMESTAMP}, #{updateTime,jdbcType=TIMESTAMP})
  </insert>
  <insert id="insertSelective" parameterType="com.liubo.hadoop.dao.entity.FileInfo">
    insert into file_info
    <trim prefix="(" suffix=")" suffixOverrides=",">
      <if test="id != null">
        id,
      </if>
      <if test="fileNo != null">
        file_no,
      </if>
      <if test="fileName != null">
        file_name,
      </if>
      <if test="fileType != null">
        file_type,
      </if>
      <if test="fileAuthor != null">
        file_author,
      </if>
      <if test="fileDesc != null">
        file_desc,
      </if>
      <if test="fileSize != null">
        file_size,
      </if>
      <if test="fileUrl != null">
        file_url,
      </if>
      <if test="userId != null">
        user_id,
      </if>
      <if test="createTime != null">
        create_time,
      </if>
      <if test="updateTime != null">
        update_time,
      </if>
    </trim>
    <trim prefix="values (" suffix=")" suffixOverrides=",">
      <if test="id != null">
        #{id,jdbcType=INTEGER},
      </if>
      <if test="fileNo != null">
        #{fileNo,jdbcType=VARCHAR},
      </if>
      <if test="fileName != null">
        #{fileName,jdbcType=VARCHAR},
      </if>
      <if test="fileType != null">
        #{fileType,jdbcType=VARCHAR},
      </if>
      <if test="fileAuthor != null">
        #{fileAuthor,jdbcType=VARCHAR},
      </if>
      <if test="fileDesc != null">
        #{fileDesc,jdbcType=VARCHAR},
      </if>
      <if test="fileSize != null">
        #{fileSize,jdbcType=BIGINT},
      </if>
      <if test="fileUrl != null">
        #{fileUrl,jdbcType=VARCHAR},
      </if>
      <if test="userId != null">
        #{userId,jdbcType=VARCHAR},
      </if>
      <if test="createTime != null">
        #{createTime,jdbcType=TIMESTAMP},
      </if>
      <if test="updateTime != null">
        #{updateTime,jdbcType=TIMESTAMP},
      </if>
    </trim>
  </insert>
  <update id="updateByPrimaryKeySelective" parameterType="com.liubo.hadoop.dao.entity.FileInfo">
    update file_info
    <set>
      <if test="fileNo != null">
        file_no = #{fileNo,jdbcType=VARCHAR},
      </if>
      <if test="fileName != null">
        file_name = #{fileName,jdbcType=VARCHAR},
      </if>
      <if test="fileType != null">
        file_type = #{fileType,jdbcType=VARCHAR},
      </if>
      <if test="fileAuthor != null">
        file_author = #{fileAuthor,jdbcType=VARCHAR},
      </if>
      <if test="fileDesc != null">
        file_desc = #{fileDesc,jdbcType=VARCHAR},
      </if>
      <if test="fileSize != null">
        file_size = #{fileSize,jdbcType=BIGINT},
      </if>
      <if test="fileUrl != null">
        file_url = #{fileUrl,jdbcType=VARCHAR},
      </if>
      <if test="userId != null">
        user_id = #{userId,jdbcType=VARCHAR},
      </if>
      <if test="createTime != null">
        create_time = #{createTime,jdbcType=TIMESTAMP},
      </if>
      <if test="updateTime != null">
        update_time = #{updateTime,jdbcType=TIMESTAMP},
      </if>
    </set>
    where id = #{id,jdbcType=INTEGER}
  </update>
  <update id="updateByPrimaryKey" parameterType="com.liubo.hadoop.dao.entity.FileInfo">
    update file_info
    set file_no = #{fileNo,jdbcType=VARCHAR},
      file_name = #{fileName,jdbcType=VARCHAR},
      file_type = #{fileType,jdbcType=VARCHAR},
      file_author = #{fileAuthor,jdbcType=VARCHAR},
      file_desc = #{fileDesc,jdbcType=VARCHAR},
      file_size = #{fileSize,jdbcType=BIGINT},
      file_url = #{fileUrl,jdbcType=VARCHAR},
      user_id = #{userId,jdbcType=VARCHAR},
      create_time = #{createTime,jdbcType=TIMESTAMP},
      update_time = #{updateTime,jdbcType=TIMESTAMP}
    where id = #{id,jdbcType=INTEGER}
  </update>
</mapper>